"""YOLOv11 + DINOv2 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸"""

import argparse
import torch
import torch.nn as nn
from ultralytics import YOLO
from torchvision import transforms
from PIL import Image
import yaml
import os
import cv2
import numpy as np
from pathlib import Path
from datetime import datetime
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns


class DINOv2Classifier(nn.Module):
    """DINOv2 ë¶„ë¥˜ ëª¨ë¸ (ì²´í¬í¬ì¸íŠ¸ ë¡œë”©ìš©)"""
    def __init__(self, backbone, embed_dim, num_classes=2):
        super().__init__()
        self.backbone = backbone
        self.classifier = nn.Sequential(
            nn.Linear(embed_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        return self.classifier(features)


class YOLODINOPipeline:
    def __init__(self, mode='frontdoor', yolo_model_path=None, 
                 dino_models=None, device='cuda', conf_threshold=0.25,
                 voting_method='soft', project_name='pipeline_test'):
        """
        YOLO + DINOv2 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸
        
        Args:
            mode (str): 'frontdoor' ë˜ëŠ” 'bolt'
            yolo_model_path (str): YOLO ëª¨ë¸ ê²½ë¡œ
            dino_models (dict): DINOv2 ëª¨ë¸ ê²½ë¡œë“¤
                - frontdoor: {'high': path, 'mid': path, 'low': path}
                - bolt: {'bolt': path}
            device (str): ë””ë°”ì´ìŠ¤
            conf_threshold (float): YOLO ì‹ ë¢°ë„ ì„ê³„ê°’
            voting_method (str): 'hard' ë˜ëŠ” 'soft' (frontdoorìš©)
            project_name (str): í”„ë¡œì íŠ¸ ì´ë¦„ (ê²°ê³¼ í´ë”ëª…ì— ì‚¬ìš©)
        """
        self.mode = mode.lower()
        self.device = device if torch.cuda.is_available() else 'cpu'
        self.conf_threshold = conf_threshold
        self.voting_method = voting_method
        self.project_name = project_name
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        if yolo_model_path is None:
            raise ValueError("YOLO ëª¨ë¸ ê²½ë¡œë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        print(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë“œ ì¤‘: {yolo_model_path}")
        self.yolo_model = YOLO(yolo_model_path)
        
        # DINOv2 ëª¨ë¸ ë¡œë“œ
        self.dino_models = {}
        if dino_models is None:
            raise ValueError("DINOv2 ëª¨ë¸ ê²½ë¡œë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        
        if self.mode == 'frontdoor':
            required_keys = ['high', 'mid', 'low']
            for key in required_keys:
                if key not in dino_models:
                    raise ValueError(f"frontdoor ëª¨ë“œëŠ” {required_keys} ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            for part, model_path in dino_models.items():
                print(f"ğŸ”„ DINOv2 ëª¨ë¸ ë¡œë“œ ì¤‘ ({part}): {model_path}")
                self.dino_models[part] = self._load_dino_model(model_path)
        
        elif self.mode == 'bolt':
            if 'bolt' not in dino_models:
                raise ValueError("bolt ëª¨ë“œëŠ” 'bolt' ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print(f"ğŸ”„ DINOv2 ëª¨ë¸ ë¡œë“œ ì¤‘ (bolt): {dino_models['bolt']}")
            self.dino_models['bolt'] = self._load_dino_model(dino_models['bolt'])
        
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë“œ: {self.mode}")
        
        # YOLO í´ë˜ìŠ¤ ë§¤í•‘ (bolt ëª¨ë“œìš©)
        self.bolt_class_names = {
            0: 'bolt_frontside',
            1: 'bolt_side',
            2: 'sedan (trunklid)',
            3: 'suv (trunklid)',
            4: 'hood',
            5: 'long (frontfender)',
            6: 'mid (frontfender)',
            7: 'short (frontfender)'
        }
        
        # DINOv2 ì „ì²˜ë¦¬
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        print(f"âœ“ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  - ëª¨ë“œ: {self.mode}")
        print(f"  - ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"  - YOLO ì‹ ë¢°ë„ ì„ê³„ê°’: {self.conf_threshold}")
        if self.mode == 'frontdoor':
            print(f"  - Voting ë°©ë²•: {self.voting_method}")
    
    def _load_dino_model(self, model_path):
        """DINOv2 ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        checkpoint = torch.load(model_path, map_location=self.device)
        config = checkpoint.get('config', {})
        
        model_size = config.get('model_size', 'small')
        num_classes = config.get('num_classes', 2)
        
        # ë°±ë³¸ ë¡œë“œ
        model_map = {
            'small': ('dinov2_vits14', 384),
            'base': ('dinov2_vitb14', 768),
            'large': ('dinov2_vitl14', 1024),
            'giant': ('dinov2_vitg14', 1536)
        }
        model_name, embed_dim = model_map.get(model_size, ('dinov2_vits14', 384))
        
        backbone = torch.hub.load('facebookresearch/dinov2', model_name)
        model = DINOv2Classifier(backbone, embed_dim, num_classes)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        return model
    
    def _extract_gt_label(self, img_path):
        """
        ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ GT ë¼ë²¨ ì¶”ì¶œ
        ê²½ë¡œì— 'bad' ë˜ëŠ” 'defect'ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ‰(1), 'good'ì´ ìˆìœ¼ë©´ ì–‘í’ˆ(0)
        """
        path_lower = img_path.lower()
        
        # ê²½ë¡œë¥¼ '/'ë¡œ ë¶„í• í•˜ì—¬ í´ë”ëª… í™•ì¸
        parts = path_lower.split('/')
        
        if 'bad' in parts or 'defect' in parts:
            return 1  # ë¶ˆëŸ‰
        elif 'good' in parts:
            return 0  # ì–‘í’ˆ
        else:
            # íŒŒì¼ëª…ì—ì„œë„ í™•ì¸
            filename = os.path.basename(path_lower)
            if 'bad' in filename or 'defect' in filename:
                return 1
            elif 'good' in filename:
                return 0
            else:
                return None  # GTë¥¼ ì•Œ ìˆ˜ ì—†ìŒ
    
    def process_image_list(self, txt_file):
        """
        ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        
        Args:
            txt_file (str): ì´ë¯¸ì§€ ê²½ë¡œê°€ ë‹´ê¸´ txt íŒŒì¼
        """
        # ê²°ê³¼ í´ë” ìƒì„±
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_dir = Path('runs') / f"{self.project_name}_{timestamp}"
        result_dir.mkdir(parents=True, exist_ok=True)
        
        # í•˜ìœ„ í´ë” ìƒì„±
        crops_dir = result_dir / 'crops'
        vis_dir = result_dir / 'visualizations'
        crops_dir.mkdir(exist_ok=True)
        vis_dir.mkdir(exist_ok=True)
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ì½ê¸°
        with open(txt_file, 'r') as f:
            image_paths = [line.strip() for line in f if line.strip()]
        
        print(f"\n{'='*60}")
        print(f"ğŸš€ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘")
        print(f"{'='*60}")
        print(f"  - ì´ ì´ë¯¸ì§€ ìˆ˜: {len(image_paths)}")
        print(f"  - ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {result_dir}\n")
        
        results = []
        y_true = []
        y_pred = []
        
        for idx, img_path in enumerate(tqdm(image_paths, desc="Processing")):
            if not os.path.exists(img_path):
                print(f"âš ï¸  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
                continue
            
            # GT ë¼ë²¨ ì¶”ì¶œ
            gt_label = self._extract_gt_label(img_path)
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            result = self.process_single_image(
                img_path, 
                result_dir, 
                crops_dir, 
                vis_dir, 
                idx,
                gt_label
            )
            results.append(result)
            
            # confusion matrixìš© ë°ì´í„° ìˆ˜ì§‘
            if gt_label is not None and result['status'] in ['processed', 'defect']:
                y_true.append(gt_label)
                pred_label = 1 if result['final_prediction'] == 'defect' else 0
                y_pred.append(pred_label)
        
        # ê²°ê³¼ ì €ì¥
        self._save_results(results, result_dir)
        
        # Confusion Matrix ìƒì„±
        if len(y_true) > 0:
            self._plot_confusion_matrix(y_true, y_pred, result_dir)
        
        # í†µê³„ ì¶œë ¥
        self._print_statistics(results, y_true, y_pred)
        
        return results
    
    def process_single_image(self, img_path, result_dir, crops_dir, vis_dir, idx, gt_label):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img = cv2.imread(img_path)
            if img is None:
                return {
                    'image_path': img_path,
                    'status': 'error',
                    'message': 'Failed to load image',
                    'gt_label': gt_label
                }
            
            # YOLO ê²€ì¶œ
            yolo_results = self.yolo_model.predict(
                img_path, 
                conf=self.conf_threshold,
                verbose=False
            )[0]
            
            boxes = yolo_results.boxes
            
            if self.mode == 'frontdoor':
                result = self._process_frontdoor(
                    img, img_path, boxes, crops_dir, vis_dir, idx, gt_label
                )
            elif self.mode == 'bolt':
                result = self._process_bolt(
                    img, img_path, boxes, crops_dir, vis_dir, idx, gt_label
                )
            
            result['gt_label'] = gt_label
            return result
        
        except Exception as e:
            import traceback
            return {
                'image_path': img_path,
                'status': 'error',
                'message': str(e),
                'traceback': traceback.format_exc(),
                'gt_label': gt_label
            }
    
    def _process_frontdoor(self, img, img_path, boxes, crops_dir, vis_dir, idx, gt_label):
        """í”„ë¡ íŠ¸ë„ì–´ ì²˜ë¦¬"""
        # í´ë˜ìŠ¤ë³„ ê²€ì¶œ ê²°ê³¼ ì •ë¦¬
        detections = {'high': [], 'mid': [], 'low': []}
        
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            xyxy = box.xyxy[0].cpu().numpy()
            
            class_name = self.yolo_model.names[cls_id].lower()
            if class_name in detections:
                detections[class_name].append({
                    'bbox': xyxy,
                    'conf': conf
                })
        
        # ì¡°ê±´ í™•ì¸: high/mid/low ê° 1ê°œì”© OR high/low ê° 1ê°œì”©
        has_all_three = (len(detections['high']) == 1 and 
                        len(detections['mid']) == 1 and 
                        len(detections['low']) == 1)
        has_high_low = (len(detections['high']) == 1 and 
                       len(detections['low']) == 1 and 
                       len(detections['mid']) == 0)
        
        if not (has_all_three or has_high_low):
            # ì‹œê°í™” (ê²€ì¶œ ì‹¤íŒ¨)
            self._save_visualization(
                img, img_path, [], vis_dir, idx, 
                'skipped', gt_label, None
            )
            return {
                'image_path': img_path,
                'status': 'skipped',
                'message': 'Detection condition not met',
                'detections': {k: len(v) for k, v in detections.items()}
            }
        
        # ê° ë¶€ìœ„ë³„ í¬ë¡­ ë° ë¶„ë¥˜
        part_results = {}
        parts_to_process = ['high', 'mid', 'low'] if has_all_three else ['high', 'low']
        crop_info = []
        
        for part in parts_to_process:
            if len(detections[part]) > 0:
                bbox = detections[part][0]['bbox']
                x1, y1, x2, y2 = map(int, bbox)
                cropped = img[y1:y2, x1:x2]
                
                # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥
                crop_filename = f"{idx:04d}_{part}.jpg"
                crop_path = crops_dir / crop_filename
                cv2.imwrite(str(crop_path), cropped)
                
                # DINOv2 ë¶„ë¥˜
                pred_class, confidence = self._classify_with_dino(cropped, part)
                
                part_results[part] = {
                    'bbox': bbox.tolist(),
                    'yolo_conf': detections[part][0]['conf'],
                    'pred_class': pred_class,
                    'confidence': confidence,
                    'crop_path': str(crop_path)
                }
                
                crop_info.append({
                    'bbox': bbox,
                    'label': f"{part}: {'Bad' if pred_class == 1 else 'Good'} ({confidence[pred_class]:.2f})",
                    'color': (0, 0, 255) if pred_class == 1 else (0, 255, 0)
                })
        
        # Voting
        if self.voting_method == 'hard':
            final_pred = self._hard_voting(part_results)
        else:  # soft
            final_pred = self._soft_voting(part_results)
        
        # ì‹œê°í™” ì €ì¥
        self._save_visualization(
            img, img_path, crop_info, vis_dir, idx, 
            final_pred, gt_label, part_results
        )
        
        return {
            'image_path': img_path,
            'status': 'processed',
            'mode': 'frontdoor',
            'parts': part_results,
            'final_prediction': final_pred,
            'voting_method': self.voting_method
        }
    
    def _process_bolt(self, img, img_path, boxes, crops_dir, vis_dir, idx, gt_label):
        """ë³¼íŠ¸ ì²˜ë¦¬"""
        # í´ë˜ìŠ¤ë³„ ê²€ì¶œ ê²°ê³¼ ì •ë¦¬
        bolt_detections = []  # 0, 1ë²ˆ í´ë˜ìŠ¤ (ë³¼íŠ¸)
        frame_detections = []  # 2~7ë²ˆ í´ë˜ìŠ¤ (í”„ë ˆì„)
        
        for box in boxes:
            cls_id = int(box.cls[0])
            conf = float(box.conf[0])
            xyxy = box.xyxy[0].cpu().numpy()
            
            detection = {
                'class_id': cls_id,
                'class_name': self.bolt_class_names.get(cls_id, 'unknown'),
                'bbox': xyxy,
                'conf': conf,
                'center': [(xyxy[0] + xyxy[2]) / 2, (xyxy[1] + xyxy[3]) / 2]
            }
            
            if cls_id in [0, 1]:  # ë³¼íŠ¸
                bolt_detections.append(detection)
            elif cls_id in [2, 3, 4, 5, 6, 7]:  # í”„ë ˆì„
                frame_detections.append(detection)
        
        # 2~7ë²ˆ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if len(frame_detections) == 0:
            self._save_visualization(
                img, img_path, [], vis_dir, idx, 
                'skipped', gt_label, None
            )
            return {
                'image_path': img_path,
                'status': 'skipped',
                'message': 'No frame detection (class 2-7)',
                'bolt_count': len(bolt_detections),
                'frame_count': len(frame_detections)
            }
        
        # ê° í”„ë ˆì„ ì˜ì—­ ë‚´ì˜ ë³¼íŠ¸ ì°¾ê¸°
        valid_bolts = []
        for frame in frame_detections:
            frame_bbox = frame['bbox']
            frame_cls = frame['class_id']
            
            # ì´ í”„ë ˆì„ ë‚´ì˜ ë³¼íŠ¸ë“¤
            bolts_in_frame = []
            for bolt in bolt_detections:
                cx, cy = bolt['center']
                if (frame_bbox[0] <= cx <= frame_bbox[2] and 
                    frame_bbox[1] <= cy <= frame_bbox[3]):
                    bolts_in_frame.append(bolt)
            
            # í”„ë ˆì„ ì¢…ë¥˜ê°€ 2, 3, 4ë²ˆì¼ ë•Œ ë³¼íŠ¸ ê°œìˆ˜ ì²´í¬ (sedan, suv, hood)
            if frame_cls in [2, 3, 4]:
                if len(bolts_in_frame) != 2:
                    self._save_visualization(
                        img, img_path, [], vis_dir, idx, 
                        'defect', gt_label, None
                    )
                    return {
                        'image_path': img_path,
                        'status': 'defect',
                        'reason': 'bolt_count_mismatch',
                        'frame_class': frame['class_name'],
                        'expected_bolts': 2,
                        'actual_bolts': len(bolts_in_frame),
                        'final_prediction': 'defect'
                    }
            
            valid_bolts.extend(bolts_in_frame)
        
        # ë³¼íŠ¸ê°€ ì—†ìœ¼ë©´ ë¶ˆëŸ‰
        if len(valid_bolts) == 0:
            self._save_visualization(
                img, img_path, [], vis_dir, idx, 
                'defect', gt_label, None
            )
            return {
                'image_path': img_path,
                'status': 'defect',
                'reason': 'no_bolts_in_frame',
                'final_prediction': 'defect'
            }
        
        # ê° ë³¼íŠ¸ë¥¼ DINOv2ë¡œ ë¶„ë¥˜
        bolt_results = []
        crop_info = []
        
        for bolt_idx, bolt in enumerate(valid_bolts):
            bbox = bolt['bbox']
            x1, y1, x2, y2 = map(int, bbox)
            cropped = img[y1:y2, x1:x2]
            
            # í¬ë¡­ ì´ë¯¸ì§€ ì €ì¥
            crop_filename = f"{idx:04d}_bolt_{bolt_idx}.jpg"
            crop_path = crops_dir / crop_filename
            cv2.imwrite(str(crop_path), cropped)
            
            pred_class, confidence = self._classify_with_dino(cropped, 'bolt')
            
            bolt_results.append({
                'bbox': bbox.tolist(),
                'yolo_class': bolt['class_name'],
                'yolo_conf': bolt['conf'],
                'pred_class': pred_class,
                'confidence': confidence,
                'crop_path': str(crop_path)
            })
            
            crop_info.append({
                'bbox': bbox,
                'label': f"Bolt: {'Bad' if pred_class == 1 else 'Good'} ({confidence[pred_class]:.2f})",
                'color': (0, 0, 255) if pred_class == 1 else (0, 255, 0)
            })
        
        # í•˜ë‚˜ë¼ë„ ë¶ˆëŸ‰ì´ë©´ ì „ì²´ ë¶ˆëŸ‰
        has_defect = any(b['pred_class'] == 1 for b in bolt_results)
        final_pred = 'defect' if has_defect else 'good'
        
        # ì‹œê°í™” ì €ì¥
        self._save_visualization(
            img, img_path, crop_info, vis_dir, idx, 
            final_pred, gt_label, bolt_results
        )
        
        return {
            'image_path': img_path,
            'status': 'processed',
            'mode': 'bolt',
            'bolt_count': len(valid_bolts),
            'bolt_results': bolt_results,
            'final_prediction': final_pred
        }
    
    def _save_visualization(self, img, img_path, crop_info, vis_dir, idx, 
                           prediction, gt_label, detail_results):
        """ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥"""
        vis_img = img.copy()
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for crop in crop_info:
            bbox = crop['bbox']
            label = crop['label']
            color = crop['color']
            
            x1, y1, x2, y2 = map(int, bbox)
            cv2.rectangle(vis_img, (x1, y1), (x2, y2), color, 2)
            
            # ë¼ë²¨ ë°°ê²½
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            cv2.rectangle(vis_img, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            cv2.putText(vis_img, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # ì˜¤ë¥¸ìª½ ìƒë‹¨ì— ê²°ê³¼ í‘œì‹œ
        h, w = vis_img.shape[:2]
        
        # GT vs Prediction ë¹„êµ
        if gt_label is not None:
            gt_text = "GT: Good" if gt_label == 0 else "GT: Bad"
            pred_text = f"Pred: {prediction.capitalize()}"
            
            # ì •ë‹µ ì—¬ë¶€ íŒë‹¨
            pred_label = 1 if prediction == 'defect' else 0
            is_correct = (gt_label == pred_label)
            result_symbol = "âœ“" if is_correct else "âœ—"
            result_color = (0, 255, 0) if is_correct else (0, 0, 255)
            
            # ë°°ê²½ ì‚¬ê°í˜•
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 110), (0, 0, 0), -1)
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 110), (255, 255, 255), 2)
            
            # í…ìŠ¤íŠ¸
            cv2.putText(vis_img, gt_text, (w - 240, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(vis_img, pred_text, (w - 240, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(vis_img, result_symbol, (w - 240, 100), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, result_color, 3)
        else:
            # GT ì—†ëŠ” ê²½ìš°
            pred_text = f"Pred: {prediction.capitalize()}"
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 60), (0, 0, 0), -1)
            cv2.rectangle(vis_img, (w - 250, 10), (w - 10, 60), (255, 255, 255), 2)
            cv2.putText(vis_img, pred_text, (w - 240, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ì €ì¥
        vis_filename = f"{idx:04d}_vis.jpg"
        vis_path = vis_dir / vis_filename
        cv2.imwrite(str(vis_path), vis_img)
    
    def _classify_with_dino(self, cropped_img, part):
        """DINOv2ë¡œ í¬ë¡­ëœ ì´ë¯¸ì§€ ë¶„ë¥˜"""
        if cropped_img.size == 0:
            return 1, [0.0, 1.0]  # ë¹ˆ ì´ë¯¸ì§€ëŠ” ë¶ˆëŸ‰ìœ¼ë¡œ
        
        # BGR to RGB
        cropped_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(cropped_rgb)
        
        # ì „ì²˜ë¦¬
        img_tensor = self.transform(pil_img).unsqueeze(0).to(self.device)
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = self.dino_models[part](img_tensor)
            probs = torch.softmax(outputs, dim=1)
            pred_class = torch.argmax(probs, dim=1).item()
            confidence = probs[0].cpu().numpy().tolist()
        
        return pred_class, confidence
    
    def _hard_voting(self, part_results):
        """Hard Voting: ë‹¤ìˆ˜ê²°"""
        votes = [result['pred_class'] for result in part_results.values()]
        defect_count = sum(votes)
        
        # ê³¼ë°˜ìˆ˜ ì´ìƒì´ ë¶ˆëŸ‰ì´ë©´ ë¶ˆëŸ‰
        if defect_count > len(votes) / 2:
            return 'defect'
        else:
            return 'good'
    
    def _soft_voting(self, part_results):
        """Soft Voting: í‰ê·  confidence"""
        # ê° ë¶€ìœ„ì˜ ë¶ˆëŸ‰(class 1) confidence í‰ê· 
        defect_confidences = [result['confidence'][1] for result in part_results.values()]
        avg_defect_conf = sum(defect_confidences) / len(defect_confidences)
        
        # í‰ê· ì´ 0.5 ì´ìƒì´ë©´ ë¶ˆëŸ‰
        if avg_defect_conf > 0.5:
            return 'defect'
        else:
            return 'good'
    
    def _save_results(self, results, result_dir):
        """ê²°ê³¼ ì €ì¥"""
        output_file = result_dir / 'results.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nâœ“ ê²°ê³¼ ì €ì¥: {output_file}")
    
    def _plot_confusion_matrix(self, y_true, y_pred, result_dir):
        """Confusion Matrix ìƒì„± ë° ì €ì¥"""
        # Confusion Matrix ê³„ì‚°
        cm = [[0, 0], [0, 0]]  # [[TN, FP], [FN, TP]]
        
        for true, pred in zip(y_true, y_pred):
            cm[true][pred] += 1
        
        # ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(8, 6))
        
        # Heatmap
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Good', 'Defect'],
                   yticklabels=['Good', 'Defect'],
                   ax=ax, cbar_kws={'label': 'Count'})
        
        ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
        ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
        ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        cm_path = result_dir / 'confusion_matrix.png'
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ Confusion Matrix ì €ì¥: {cm_path}")
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]
        total = tn + fp + fn + tp
        
        accuracy = (tp + tn) / total if total > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        metrics = {
            'confusion_matrix': {
                'TN': int(tn), 'FP': int(fp),
                'FN': int(fn), 'TP': int(tp)
            },
            'metrics': {
                'accuracy': float(accuracy),
                'precision': float(precision),
                'recall': float(recall),
                'f1_score': float(f1)
            }
        }
        
        metrics_path = result_dir / 'metrics.json'
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2)
        
        print(f"âœ“ ë©”íŠ¸ë¦­ ì €ì¥: {metrics_path}")
        
        return metrics


def parse_args():
    parser = argparse.ArgumentParser(description="YOLO + DINOv2 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸")
    parser.add_argument("--config", required=True, type=str, help="ëª¨ë¸ ê²½ë¡œë“¤ì´ ë“¤ì–´ìˆëŠ” YAML íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--txt", required=True, type=str, help="ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡ì´ ë‹´ê¸´ txt íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--mode", required=True, choices=["frontdoor", "bolt"], help="ì‹¤í–‰ ëª¨ë“œ")
    parser.add_argument("--voting", default="soft", choices=["soft", "hard"], help="frontdoor ëª¨ë“œì—ì„œì˜ ë³´íŒ… ë°©ì‹")
    parser.add_argument("--project", default="pipeline_test", type=str, help="runs í•˜ìœ„ ê²°ê³¼ í´ë”ëª… prefix")
    parser.add_argument("--conf", default=0.25, type=float, help="YOLO ì‹ ë¢°ë„ ì„ê³„ê°’")
    parser.add_argument("--device", default="cuda", type=str, help="ë””ë°”ì´ìŠ¤ (cuda|cpu)")
    return parser.parse_args()


def load_models_from_yaml(config_path, mode):
    with open(config_path, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    # YAMLì€ ëª¨ë¸ ê²½ë¡œë§Œ í¬í•¨í•œë‹¤ê³  ê°€ì •
    yolo_model_path = cfg.get("yolo_model") or cfg.get("yolo") or cfg.get("yolo_model_path")
    if yolo_model_path is None:
        raise ValueError("YAMLì— 'yolo_model' ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    dino_models = {}
    if mode == "frontdoor":
        # ì˜ˆìƒ í‚¤: high, mid, low
        for key in ["high", "mid", "low"]:
            if key not in cfg:
                raise ValueError("frontdoor ëª¨ë“œëŠ” YAMLì— 'high', 'mid', 'low' í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            dino_models[key] = cfg[key]
    else:
        # bolt ëª¨ë“œ: bolt ë‹¨ì¼ í‚¤
        bolt_path = cfg.get("bolt")
        if bolt_path is None:
            raise ValueError("bolt ëª¨ë“œëŠ” YAMLì— 'bolt' í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        dino_models["bolt"] = bolt_path

    return yolo_model_path, dino_models


def main():
    args = parse_args()

    # YAMLì—ì„œ ê²½ë¡œë“¤ ë¡œë“œ
    yolo_model_path, dino_models = load_models_from_yaml(args.config, args.mode)

    # íŒŒì´í”„ë¼ì¸ ìƒì„±
    pipeline = YOLODINOPipeline(
        mode=args.mode,
        yolo_model_path=yolo_model_path,
        dino_models=dino_models,
        device=args.device,
        conf_threshold=args.conf,
        voting_method=args.voting,
        project_name=args.project,
    )

    # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
    pipeline.process_image_list(args.txt)


if __name__ == "__main__":
    main()